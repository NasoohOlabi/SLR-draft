\section{Introduction}
\label{sec:introduction}

This review explores how large language models (LLMs) are transforming linguistic steganography, the practice of hiding messages in text. We focus on the unique challenges and advances in using LLMs for secure, imperceptible, and high-capacity covert communication.

\subsection{Overview of Information Security and Concealment Systems}
Information security systems include \textbf{encryption}, \textbf{privacy}, and \textbf{concealment} (steganography).

\subsubsection{Encryption Systems and Privacy Systems}
These protect content but reveal that secret communication is happening, which can attract attention.

\subsubsection{Concealment Systems (Steganography)}
Steganography hides the existence of information by embedding it in ordinary carriers (e.g., text, images). Text is a challenging carrier due to its low redundancy and strict semantics.

\subsection{Introduction to Steganography}
Steganography is often explained by the ``Prisoners' Problem,'' where Alice and Bob must communicate secretly under surveillance. The goal is to embed messages so they are undetectable to an observer.

Steganography methods include \textbf{carrier selection}, \textbf{carrier modification}, and \textbf{carrier generation}.
\begin{itemize}
    \item \textbf{Carrier modification:} Hide information in existing text with minimal changes.
    \item \textbf{Carrier generation:} Generate new text that encodes information, allowing higher capacity but requiring naturalness.
\end{itemize}

\subsection{The Significance of Linguistic Steganography}
Linguistic steganography enables covert communication, especially where encryption is suspicious. Text is a robust, ubiquitous carrier but presents challenges in balancing imperceptibility and capacity. Advances in deep learning and LLMs improve text quality and security, while related fields like watermarking focus on tracing content origin.

\subsection{The Emergence of Large Language Models (LLMs)}

Large Language Models (LLMs) have emerged as a significant development in the field of natural language processing, profoundly impacting text generation and related applications like steganography and watermarking. Here's a breakdown of their emergence and impact:

\begin{itemize}
    \item \textbf{Capabilities and Approximating Natural Communication}
    \begin{itemize}
        \item LLMs are \textbf{generative models} that can \textbf{approximate complex distributions like text-based communication}. They represent the best-known technique for this task.
        \item These models operate by taking context and parameters to output an explicit probability distribution over the next token (e.g., a character or a word). The next token is typically sampled randomly from this distribution, and the process repeats to generate output of a desired length.
        \item Training LLMs involves processing vast amounts of data to set parameters and structure, enabling their output distributions to approximate true distributions in the training data.
        \item The \textbf{quality of content generated by generative models is impressive} and continues to improve. This has led to LLMs blurring the boundary of high-quality text generation between humans and machines.
        \item LLMs are increasingly used to generate data for specific tasks, such as tabular data, relational triples, sentence pairs, and instruction data, often achieving satisfactory generation quality in zero-shot learning for specific subject categories.
        \item They have also shown capabilities in mimicking language styles and semantics, and their generalization ability allows them to comprehend the semantics of context.
    \end{itemize}

    \item \textbf{Role in Generative Linguistic Steganography}
    \begin{itemize}
        \item LLMs are considered \textbf{favorable for generative text steganography} due to their ability to generate high-quality text.
        \item Researchers propose using generative models as steganographic samplers to embed messages into realistic communication distributions, such as text. This is a departure from prior steganographic work and is motivated by the public availability of high-quality models and significant efficiency gains.
        \item LLMs like \textbf{GPT-2, LLaMA, and Baichuan2} are commonly used as basic generative models for steganography.
        \item Existing methods often use a language model and steganographic mapping, where secret messages are embedded by establishing a mapping between binary bits and the sampling probability of words within the training vocabulary.
        \item However, traditional "white-box" methods require sharing the exact language model and training vocabulary, which limits fluency, logic, and diversity compared to natural texts generated by LLMs. They also inevitably change the sampling probability distribution, posing security risks.
        \item New approaches, like \textbf{LLM-Stega}, explore \textbf{black-box generative text steganography using the user interfaces (UIs) of LLMs}, overcoming the need to access internal sampling distributions. This method constructs a keyword set and uses an encrypted steganographic mapping for embedding, proposing an optimization mechanism based on reject sampling for accurate extraction and rich semantics.
        \item Another framework, \textbf{Co-Stega}, leverages LLMs to address the low capacity challenge in social media by increasing the text space for hiding messages (through context retrieval) and \textbf{raising the generated text's entropy via specific prompts} to increase embedding capacity. This approach also aims to maintain text quality, fluency, and relevance.
        \item The concept of \textbf{zero-shot linguistic steganography} with LLMs utilizes in-context learning, where samples of covertext are used as context to generate more intelligible stegotext using a question-answer (QA) paradigm.
        \item LLMs are also used in approaches like \textbf{ALiSa}, which directly conceals token-level secret messages in seemingly natural steganographic text generated by off-the-shelf BERT models equipped with Gibbs sampling.
        \item The increasing popularity of deep generative models has made it feasible for provably secure steganography to be applied in real-world scenarios, as they fulfill requirements for perfect samplers and explicit data distributions.
    \end{itemize}

    \item \textbf{Challenges and Limitations in Steganography with LLMs}
    \begin{itemize}
        \item Despite their capabilities, generative models are still \textbf{far from perfect} in imitating real communication.
        \item A significant challenge for practical steganography is the difficulty of finding samplers for non-trivial distributions like the English language, which continues to evolve.
        \item When using approximate samplers, there's a risk that an adversary can detect a steganographic message by distinguishing between the real channel and the approximation.
        \item LLMs are known to make mistakes, including "hallucinations," which can lead to errors and erratic embedding during text generation, especially for long stego sequences.
        \item One critical issue is \textbf{segmentation ambiguity} in neural linguistic steganography. LLMs often use \textbf{subword tokenization}, meaning a single text can correspond to multiple token representations. If the sender and receiver have different understandings of segmentation, it can lead to incorrect message extraction and affect subsequent generation steps. Current provably secure methods have largely overlooked this. SyncPool is a proposed method to address this by grouping tokens with prefix relationships in the candidate pool without altering the original probability distribution.
        \item The \textbf{computational overhead of LLMs is higher} compared to prior methods (approximately 3x to 5x), potentially limiting real-time communication.
        \item The effectiveness of LLM-based steganography can be limited by the \textbf{entropy of the cover text} in social media contexts, as short, context-dependent replies have lower entropy, thus limiting hiding capacity.
    \end{itemize}
\end{itemize}

\subsection{Scope of the Review}
This review covers LLM-based linguistic steganography, focusing on methods, evaluation, challenges, and future directions.