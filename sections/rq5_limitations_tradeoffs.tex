\subsection{Limitations and Trade-offs in Current Techniques (RQ5)}
\label{subsec:rq5}

Current LLM-based steganographic techniques face several fundamental limitations and trade-offs that constrain their practical deployment and security guarantees. Understanding these limitations is crucial for advancing the field and developing more robust solutions.



\subsubsection{The Perceptual-Statistical Imperceptibility Conflict (Psic Effect)} constitutes a fundamental paradigm in generative steganography wherein optimization for perceptual fidelity inevitably degrades statistical security. This tension arises because aggressive minimization of perplexity (PPL) yields text with unnaturally ``sharp'' distributional characteristics that deviate markedly from the high variance inherent to human writing, thereby increasing vulnerability to statistical detection. Consequently, as the embedding rate (bits per word) escalates, the model's forced selection of lower-probability tokens to encode payload systematically degrades text quality; however, this same expansion of the candidate pool paradoxically enhances anti-steganalysis resistance. At higher capacities, the resulting output distribution asymptotically approaches the chaotic, high-entropy patterns of natural language, effectively camouflaging the steganographic signal within the statistical noise of legitimate human text \cite{yang2020vae}.

\subsubsection{Attack Vulnerability and Security Concerns}

Current techniques demonstrate significant vulnerability to various attacks:

\begin{itemize}
  \item \textbf{Paraphrasing Attacks:} Detection rates drop by 5-50\% when text is paraphrased
  \item \textbf{Fine-tuning Attacks:} Model fine-tuning can significantly degrade steganographic performance
  \item \textbf{Statistical Analysis:} Advanced statistical methods can detect steganographic patterns
  \item \textbf{Adversarial Examples:} Malicious inputs can compromise steganographic systems
\end{itemize}

\subsubsection{Capacity Limitations in Short Texts}

Hiding information in short, low-entropy texts presents significant challenges:

\begin{itemize}
  \item \textbf{Social Media Posts:} Limited capacity in short, informal text
  \item \textbf{Low-Entropy Content:} Technical or formal documents offer limited hiding space
  \item \textbf{Semantic Constraints:} Maintaining meaning while embedding information
  \item \textbf{Context Requirements:} Short texts may lack sufficient context for effective hiding
\end{itemize}

\subsubsection{Segmentation and Tokenization Issues}

Segmentation ambiguities, primarily from subword tokenization, create ambiguity in message extraction:

\begin{itemize}
  \item \textbf{BPE Tokenization:} Byte-pair encoding can split words unpredictably
  \item \textbf{Token Ambiguity:} Multiple valid segmentations of the same text
  \item \textbf{Extraction Errors:} Ambiguous tokenization leads to message extraction failures
  \item \textbf{Capacity Caps:} Tokenization limits maximum achievable capacity
\end{itemize}

\textbf{SparSamp} demonstrates these issues, where token ambiguity (TA) reduces accuracy, and \textbf{ShiMer} cannot effectively boost entropy due to tokenization constraints.

\subsubsection{Ethical Concerns and Misuse Potential}

The field faces significant ethical challenges that remain largely unaddressed:

\begin{itemize}
  \item \textbf{Bias and Discrimination:} Generated content may perpetuate harmful biases
  \item \textbf{Misuse Potential:} Techniques can be used for malicious purposes
  \item \textbf{Privacy Violations:} Steganographic systems may compromise user privacy
  \item \textbf{Regulatory Compliance:} Lack of frameworks for responsible use
\end{itemize}

\textbf{TrojanStego} exemplifies these concerns, as it can embed secrets directly into LLM outputs, potentially enabling data exfiltration and other malicious activities.

\subsubsection{White-box vs. Black-box Trade-offs}

The choice between white-box and black-box approaches involves fundamental trade-offs:

\begin{table}[ht]
  \centering
  \small
  \begin{tabular}{|p{3cm}|p{3cm}|p{3cm}|p{3cm}|}
    \hline
    \textbf{Aspect}  & \textbf{White-box}  & \textbf{Black-box} & \textbf{Hybrid}       \\
    \hline
    Security         & High (95-99\%)      & Medium (79-91\%)   & Medium-High (90-95\%) \\
    \hline
    Accessibility    & Low                 & High               & Medium                \\
    \hline
    Capacity         & High (1.1-5.98 bpt) & Medium (5.37 bpw)  & Medium (2.0-4.0 bpt)  \\
    \hline
    Imperceptibility & High (PPL: 3-8)     & Low (PPL: 168-363) & Medium (PPL: 50-150)  \\
    \hline
    Deployment       & Difficult           & Easy               & Moderate              \\
    \hline
  \end{tabular}
  \caption{Trade-offs between white-box, black-box, and hybrid approaches}
  \label{tab:approach_tradeoffs}
\end{table}

\subsubsection{Computational and Resource Constraints}

Computational overhead, stemming from performance optimization, often conflicts with computational efficiency:

\begin{itemize}
  \item \textbf{Computational Overhead:} Better results typically require more computational resources
  \item \textbf{Memory Requirements:} Large models and external knowledge increase memory needs
  \item \textbf{Real-time Constraints:} Latency requirements may limit optimization options
  \item \textbf{Scalability Issues:} Performance may degrade with increased scale
\end{itemize}

\textbf{UTF} demonstrates this trade-off, showing a 5\% drop in HellaSwag performance, while \textbf{FreStega} requires corpus access (100 samples) for optimal performance.

\subsubsection{Unresolved Challenges and Future Needs}

Several critical challenges remain inadequately addressed:

\begin{itemize}
  \item \textbf{Provable Security:} Lack of theoretical foundations for security guarantees
  \item \textbf{Robustness:} Limited resilience to advanced attack methods
  \item \textbf{Standardization:} Absence of common evaluation frameworks
  \item \textbf{Ethical Frameworks:} Missing guidelines for responsible development and use
  \item \textbf{Cross-lingual Support:} Poor performance in non-English languages
  \item \textbf{Real-world Deployment:} Limited testing in actual deployment scenarios
\end{itemize}

\subsubsection{Quantitative Impact Analysis}

Table \ref{tab:quantified_limitations} provides a quantitative overview of the most significant trade-offs:

\begin{table}[ht]
  \centering
  \small
  \begin{tabular}{|p{2.8cm}|p{2.8cm}|p{6.4cm}|}
    \hline
    \textbf{Limitation/Trade-off} & \textbf{Quantified Impact}           & \textbf{Examples}                                             \\
    \hline
    Psic Effect                   & $\sim$1-2 bpw loss                   & DAIRstega: Higher capacity reduces anti-steg Acc to 58\%      \\
    \hline
    Attack Vulnerability          & 5-50\% detection drop                & Ensemble WM: 98\% to 95\%; TrojanStego: 97\% to 65\%          \\
    \hline
    Entropy/Ambiguity             & Capacity cap $\sim$1023 bits         & SparSamp: TA reduces accuracy; ShiMer: Cannot boost entropy   \\
    \hline
    Ethical/Overhead              & Performance degradation $\sim$5-11\% & UTF: HellaSwag drop 5\%; FreStega: Needs corpus (100 samples) \\
    \hline
  \end{tabular}
  \caption{Quantified impact of key limitations and trade-offs}
  \label{tab:quantified_limitations}
\end{table}

Understanding these limitations and trade-offs is essential for advancing the field and developing more robust, secure, and practical steganographic systems. Future research must address these challenges to enable widespread adoption and responsible use of LLM-based steganography.
