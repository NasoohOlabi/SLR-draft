\section{Background}
\label{sec:background}

% For Ai Agents: don't touch this file without explicitly asking for permission.
% ---------------------------------------------------
% ---------------------------------------------------
% Notes: No notes for now
% ---------------------------------------------------
% ---------------------------------------------------

Information security systems broadly encompass \textbf{encryption}, \textbf{privacy}, and \textbf{concealment}, the last of which—known as \textbf{steganography}—is the focus of this review. While encryption and privacy protect message content, they do not conceal the existence of communication, which may itself arouse suspicion. Steganography instead prioritizes \textbf{imperceptibility}: embedding information into ordinary carriers (e.g., images or text) so that hidden messages remain unnoticed.

Text is a particularly challenging carrier due to its low redundancy and strict semantic constraints. The classical “Prisoners’ Problem” \cite{simmons1984prisoners} illustrates the goal: two parties, Alice and Bob, must exchange hidden information without alerting a watchful adversary.

Textual steganography methods are typically divided into \textbf{format-based} approaches, which exploit layout or structural features, and \textbf{content-based} approaches, which modify linguistic form. Within the latter, early techniques such as \textbf{synonym substitution} embed bits by altering lexical choices, but suffer from low capacity and high detectability. More formally, \textbf{linguistic steganography} refers to concealing information in natural language by modifying or generating text while preserving fluency and meaning \cite{fridrich2009steganography}.

Traditional linguistic approaches offer limited embedding capacity and often leave statistical artifacts. Advances in deep learning and \textbf{Large Language Models (LLMs)} now enable generative methods that achieve higher text quality and more secure embedding. Evaluating such systems requires several dimensions of imperceptibility: \textbf{perceptual} (human naturalness), \textbf{statistical} (distributional similarity to natural text), and \textbf{cognitive} (semantic and contextual fidelity) \cite{ding2023context}.

A deeper theoretical perspective introduces \textbf{channel entropy}, which quantifies the information-carrying capacity of a given communication channel. Entropy sets the upper bound for embedding rates: higher entropy allows more hidden information without detection, while lower entropy restricts capacity. Achieving this bound securely requires \textbf{perfect samplers}, which can generate text indistinguishable from genuine distributional samples. These concepts underpin the design of provably secure steganographic systems.

However, LLMs \cite{shanahan2024talking} introduce new challenges. Their tendency toward \textbf{hallucinations} can create detectable artifacts, highlighting the \textbf{Psic Effect} (Perceptual-Statistical Imperceptibility Conflict) \cite{yang2020vae}, where optimizing for perceptual fluency may undermine statistical security. Model access further shapes practical steganography: with \textbf{black-box access} (e.g., commercial APIs or hosted open-weight models), developers gain significantly superior text quality, faster generation speeds, and minimal local resource requirements, enabling scalable deployment without the overhead of training or hosting large models, at the cost of limited control and reduced transparency. In contrast, \textbf{white-box access} enables fine-grained control over parameters and sampling, supporting stronger security guarantees, but typically demands substantial computational resources, engineering effort, and higher latency, raising deployment barriers. This trade-off is central to evaluating the robustness and applicability of modern linguistic steganography.
