\section{Main Findings}
\label{sec:main_findings}

This section summarizes the key findings from our systematic literature review on LLM-based steganography techniques.

\subsection{Overview of LLM-based Steganography}

Large Language Models (LLMs) have revolutionized the field of linguistic steganography by providing high-quality text generation capabilities that can be leveraged for information hiding. Our review has identified several important trends and developments in this emerging field:

\begin{itemize}
    \item LLMs like GPT-2, LLaMA, and Baichuan2 are increasingly being used as the foundation for steganographic techniques due to their ability to generate natural-sounding text.
    
    \item Both white-box approaches (with access to model internals) and black-box approaches (using only model interfaces) have been developed, each with distinct advantages and limitations.
    
    \item The field faces fundamental trade-offs between imperceptibility, capacity, and security that continue to drive research innovation.
\end{itemize}

\subsection{Key Techniques and Approaches}

Our analysis identified several innovative approaches to LLM-based steganography:

\begin{itemize}
    \item \textbf{LLM-Stega} \cite{wu2024generative}: A black-box approach that uses the user interfaces of LLMs without requiring access to internal sampling distributions.
    
    \item \textbf{Co-Stega}: Leverages LLMs to expand text space for hiding messages through context retrieval and increases text entropy via specific prompts.
    
    \item \textbf{Zero-shot linguistic steganography}: Utilizes in-context learning with a question-answer paradigm to generate more natural stegotext.
    
    \item \textbf{ALiSa}: Conceals token-level secret messages in natural-looking text generated by BERT models with Gibbs sampling.
\end{itemize}

\subsection{Critical Challenges}

Despite significant progress, several challenges remain in the field of LLM-based steganography:

\begin{itemize}
    \item The Psic Effect: A fundamental trade-off between perceptual quality and statistical security.
    
    \item Limited embedding capacity, particularly in short texts with strict semantic requirements.
    
    \item Difficulties in maintaining semantic control and contextual consistency in generated steganographic text.
    
    \item Segmentation ambiguity arising from subword tokenization in LLMs.
    
    \item Ethical concerns related to potential misuse, bias, and discrimination in generated content.
\end{itemize}

\subsection{Future Outlook}

Based on our analysis, we identify several promising directions for future research:

\begin{itemize}
    \item Development of techniques that better balance perceptual quality and statistical security.
    
    \item Methods to increase embedding capacity without compromising imperceptibility.
    
    \item Approaches to improve semantic control and contextual consistency in generated text.
    
    \item Frameworks for ethical use of LLM-based steganography.
    
    \item Advancement of theoretical foundations to provide stronger security guarantees.
\end{itemize}

The rapid evolution of LLMs presents both opportunities and challenges for the field of steganography, making it an exciting area for continued research and innovation.