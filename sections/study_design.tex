\section{Literature review methodology}\label{sec:design}

\subsection{Research questions}
The research questions addressed in this systematic literature review are:
\begin{itemize}
    \item What is the state of published literature on steganographic techniques that leverage large language models (LLMs)?
    \item In which applications are steganographic techniques with LLMs being explored?
    \item What metrics and evaluation methods are used to assess the performance of steganographic techniques in LLMs, focusing on factors like capacity, security, and contextual compatibility?
    \item How are external knowledge sources (semantic resources) integrated into steganographic techniques with LLMs to enhance capacity or contextual relevance?
    \item What are the limitations and trade-offs associated with current steganographic techniques using LLMs, particularly concerning security, capacity, and contextual compatibility?
    \item What are the potential future research directions in steganography with LLMs, considering emerging trends and identified gaps in the literature?
\end{itemize}

\subsection{Search query string}
The following search query string was employed for the initial literature search:
\begin{verbatim}
(steganography or watermark or "Information Hiding")
 and ("Large Language Model" or LLM or BERT or LAMA or GPT)
\end{verbatim}

\subsection{Study selection and quality assessment}
The following inclusion and exclusion criteria were established for study selection:

\subsubsection{Inclusion Criteria}
\begin{itemize}
    \item \textbf{Full Text Access}: Studies for which the full text is available.
    \item \textbf{Language}: Publications written in English.
    \item \textbf{Peer-reviewed}: Articles published in peer-reviewed journals, conferences, or workshops.
    \item \textbf{Publication Date}: Studies published from 2018 onwards, to focus on recent advancements in LLMs.
    \item \textbf{Relevance}: Studies directly addressing steganography, watermarking, or information hiding techniques that utilize or are significantly impacted by Large Language Models (LLMs), BERT, LAMA, or GPT architectures.
    \item \textbf{Research Type}: Empirical studies, surveys, reviews, and theoretical contributions.
\end{itemize}

\subsubsection{Exclusion Criteria}
\begin{itemize}
    \item \textbf{Duplicated Studies}: Multiple publications reporting the same study will be excluded, with the most complete or recent version retained.
    \item \textbf{Incomplete or Abstract-only}: Studies for which only an abstract is available or the full text is incomplete.
    \item \textbf{Irrelevant Studies}: Publications not directly related to steganography with LLMs.
    \item \textbf{Non-English Publications}: Studies not published in English.
    \item \textbf{Non-peer-reviewed Sources}: Preprints, dissertations, theses, books, and book chapters (unless they are extended versions of peer-reviewed conference papers).
\end{itemize}

\subsection{Bibliometric analysis}
Briefly note if snowballing was used for additional sources.

\subsection{Threats to Validity}

While this systematic literature review (SLR) adheres to established guidelines such as PRISMA to ensure methodological rigor, several potential threats to validity must be acknowledged. These threats primarily relate to the comprehensiveness of the literature search, selection biases, and practical constraints in data acquisition.

First, the search strategy may introduce publication and selection biases. The query string was limited to English-language publications from 2018 onward, potentially excluding relevant non-English studies or foundational pre-2018 works on linguistic steganography that predate widespread LLM adoption. Although LLMs emerged prominently around 2018 with models such as BERT, this cutoff might overlook influential earlier contributions that inform current techniques. Additionally, the selected databases (ACM Digital Library, IEEE Digital Library, Science@Direct, Scopus, and Springer Link) provide broad coverage but may miss papers in other repositories, including arXiv, Google Scholar, or domain-specific journals. The search terms, while comprehensive, could overlook synonyms or emerging variants (e.g., "textual watermarking" without explicit LLM mentions), despite efforts to include related phrases such as "Information Hiding."

Second, biases in study selection and quality assessment could affect the review's internal validity. The inclusion criteria focused on peer-reviewed sources, which enhances reliability but may introduce publication bias by favoring positive or novel results over negative findings or gray literature. No formal risk-of-bias tool (e.g., ROBIS) was applied beyond basic relevance checks, potentially allowing lower-quality studies to influence findings. To mitigate this, multi-stage filtering with title, abstract, and full-text reviews was employed, and snowballing was used to identify additional references, though it primarily yielded older non-LLM works.

Third, practical limitations pose threats to completeness. As noted in Section 4.3, 14 papers remained pending PDF acquisition at the time of analysis, which could lead to incomplete coverage if these contain critical insights. This issue was addressed by prioritizing accessible studies and planning follow-up acquisition, but it highlights retrieval challenges in SLR processes.

Overall, these threats were minimized through transparent documentation of the methodology, adherence to PRISMA reporting standards, and supplementary snowballing. Future updates to this review could expand database coverage and incorporate automated tools for bias assessment to further enhance validity.
% The following subsections are not explicitly mentioned in the user's requested TOC, but are part of the original study_design.tex. I will keep them for now, but they might need to be merged or removed based on further instructions.
% \subsection{Data Extraction}
% Describe how data was extracted from selected studies.

% \subsection{Data Synthesis}
% Summarize the approach for synthesizing extracted data.

% \subsection{Study Replicability}
% List materials/data made available for replicability.