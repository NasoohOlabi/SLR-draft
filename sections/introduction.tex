\section{Introduction}
\label{sec:introduction}

Linguistic steganography, the practice of concealing information within natural language text, has long been regarded as one of the most challenging areas of covert communication due to the low redundancy, semantic rigidity, and statistical sensitivity of language. Traditional methods—such as synonym substitution, syntactic transformations, or rule-based embedding—often suffer from limited capacity and detectability, making them inadequate against modern steganalysis. The emergence of large language models (LLMs), however, has profoundly transformed this landscape by enabling the generation of coherent, context-aware, and statistically natural covertexts, thereby providing a foundation for high-capacity and imperceptible covert communication. This paper presents a systematic literature review that synthesizes recent advances in LLM-based linguistic steganography, identifies unresolved challenges, and highlights future research directions.

% The importance of this review lies in both the pace of recent technological developments and the gaps in existing surveys. Earlier reviews of text-based steganography have primarily emphasized classical methods and general steganographic frameworks, offering only cursory treatment of LLM-driven approaches. Yet, as Bauer et al.\ note, recent work on generative models has rapidly converged on the idea of leveraging language models to produce covertexts indistinguishable from human-authored text, with imperceptibility and capacity serving as the primary evaluation metrics \cite{bauer2024leveraging}. Similarly, Huang et al.\ emphasize that oppressive information environments increasingly motivate the use of generative methods for censorship circumvention, where the naturalness and diversity of outputs from LLMs make them particularly suited for deployment at scale \cite{huang2024oppression}. Despite these advances, no comprehensive review has yet addressed the unique challenges posed by LLM-based steganography, such as decoding ambiguity, cross-device discrepancies, or the trade-offs between statistical fidelity and contextual plausibility.

% To fill this gap, this review systematically examines 18 primary studies and 14 complementary works, consolidating fragmented progress into a coherent narrative. Specifically, it covers methods and architectures for LLM-driven embedding, evaluation metrics ranging from perplexity to embedding rate, and limitations arising from parsing ambiguity, resource constraints, and ethical risks. It also highlights how recent approaches incorporate cryptographic layers and external knowledge sources to strengthen robustness and contextual alignment. The main contributions of this paper are threefold. First, it provides the most extensive synthesis to date of LLM-based steganography, distinguishing between white-box, black-box, and hybrid approaches. Second, it introduces contextual compatibility as a unifying perspective for evaluating security and naturalness, moving beyond imperceptibility as the sole criterion. Third, it identifies open challenges—including reliability across heterogeneous deployments, discovery mechanisms for large-scale dead-drop messaging, and ethical safeguards for misuse—that future research must address. In doing so, this paper underscores the necessity of rethinking linguistic steganography in the era of LLMs, situating it as a rapidly evolving paradigm at the intersection of machine learning, cryptography, and information security.

% To address the pressing need for a comprehensive understanding of the evolving field of linguistic steganography, a systematic literature review was used as a research method for this study. A systematic literature review is aimed at providing an understanding of the scope of the research activities in this dynamic domain. Compared to a traditional literature review, a systematic literature review has many advantages, such as a well-defined methodology that reduces bias and a wider context that allows more general conclusions. The review presented in this paper aims to meticulously identify and synthesize recently published primary literature that leverages LLMs for textual steganography, quantifying the striking performance gains achieved in classic metrics like capacity and imperceptibility, particularly highlighting the potential of incorporating domain-specific knowledge and communication context for enhanced stealth and naturalness. By doing so, this review seeks to provide critical insights for researchers and practitioners, thereby informing future research directions in this rapidly advancing interdisciplinary domain.

% broad overview of how LLMs have introduced a paradigm shift toward context-aware generative text steganography. LLM-based steganography offers striking gains in classic metrics like capacity and imperceptibility. For example, the reviewed studies report that advanced white-box LLM samplers can achieve perplexities (PPL) as low as 3-8 (on GPT-2 models) while embedding up to \~5.98 bits per token. These numbers far exceed the limits of pre-LLM schemes (which often hid <1 bit/word). As the SLR authors observe, modern techniques leverage domain-specific knowledge and communication context to hide data, fulfilling both perceptual and statistical imperceptibility. In sum, the paper argues that current LLM-stealth systems can maintain natural fluency (perceptual quality) while achieving high embedding rates, overcoming “traditional limitations of low embedding capacity and cognitive imperceptibility”. This review demonstrates that LLM-based methods consistently outperform traditional text steganography under standard metrics (PPL, Kullback-Leibler divergence, embedding rate, etc.) by exploiting the rich generative power of neural language models. Significance of the Study This SLR is important because it systematically collates and analyzes a rapidly growing body of work at the intersection of steganography and LLMs. As noted in the review, no previous survey has focused on the LLM era of text hiding; earlier reviews (e.g. Majeed et al. 2021 mdpi.com) covered classical methods up to 2021 but predate widespread generative models. 

 The importance is underscored by the transformative impact of LLMs on secure communication: the survey finds a “paradigm shift toward context-aware, generative systems that prioritize imperceptibility, embedding capacity, and naturalness”. In practical terms, this means LLM-based steganography could enable secure clandestine messaging in environments (social media, censored networks, etc.) where classical stego was too limited or suspicious. By quantifying these gains and trends, this paper provides crucial insight for researchers designing the next generation of covert communication tools. Related Survey Literature Previous reviews on text steganography exist, but they focus on older techniques and do not address recent LLM-based approaches. For example, Majeed et al. (Mathematics 2021) provide a comprehensive survey of text-hiding methods and classify them into format-based, linguistic, and statistical/random-generation categories mdpi.com. They cover works from 2016-2021 across multiple languages (English, Arabic, Chinese, etc.) and outline general challenges and future directions, but do not consider deep-learning generative models. Similarly, some works review image/audio steganography broadly, but none specifically survey generative NLP schemes. In short, while prior surveys 
%\[e.g., mdpi.com\]
 identify classical approaches (synonym replacement, spacing, Huffman coding, etc.), they predate the LLM revolution. Thus there is a clear gap: no existing SLR systematically summarizes how large-scale transformers have reshaped text steganography. Justification for This Systematic Review The timing of this review is well-justified by the fast-paced developments of the last two years. LLMs like GPT-3/4 and open models (LLaMA, Baichuan, etc.) became widely available around 2022-2023, and researchers immediately began exploiting them for steganography. The review highlights that most recent studies (\~70\%) use open-source LLMs such as GPT-2, LLaMA2, and LLaMA3 to implement their systems. At the same time, novel ideas have emerged - for example, Co-Stega (2024) uses social-media context retrieval to embed messages across related posts, dramatically boosting capacity openreview\.net. These innovations have no parallel in older literature. Moreover, benchmarks indicate drastic improvements: the survey finds that modern white-box schemes can embed \~5x more data than classic systems, at far lower statistical distortion. Given this “significant surge” in publications and ideas since 2023, a timely SLR is needed to consolidate knowledge. The review also identifies new challenges and directions (e.g. cross-modal stego, ethical safeguards) that were not relevant before, making a comprehensive synthesis both novel and necessary. Paper Organization The rest of this paper follows a standard SLR structure. Section 2 provides background on steganography and LLMs, defining key concepts such as imperceptibility (perceptual, statistical, cognitive) and explaining why text is a challenging cover medium. Section 3 describes the scope and research questions of this review. Section 4 details the literature search and selection methodology (databases searched, keywords, inclusion/exclusion criteria following PRISMA guidelines). Sections 5 and 6 present the data extraction process and classification of the selected studies. Section 7 reports the results organized by research question: it summarizes the state-of-the-art techniques, application domains (covert comms, watermarking), evaluation metrics, attack models, and the role of external knowledge sources. Finally, Section 8 synthesizes the main findings and discusses trends (e.g. the shift to context-aware systems), and Section 9 concludes by outlining open problems and future research directions. Main Contributions The key contributions of this review are: Comprehensive Analysis of LLM-Steganography - We survey all relevant literature (32 papers) on generative text steganography using LLMs, providing the first systematic characterization of this emerging field. In doing so, we document striking performance gains: for instance, modern white-box methods achieve perplexities (PPL) around 3-8 while embedding up to \~5.98 bits/token. These results far exceed those of pre-LLM schemes, quantitatively demonstrating that large models can hide more data more stealthily in text. Trend Identification and Taxonomy - We identify and categorize current approaches. About 70\% of recent works rely on open LLMs (GPT-2, LLaMA2/3, etc.), while the rest use closed APIs (black-box). We note a clear hybrid: many systems incorporate digital watermarking ideas (\~40\% of papers). We also highlight novel technique clusters, such as contextual embedding (e.g. Co-Stega's use of related text threads openreview\.net) and plug-and-play distribution methods (e.g. FreStega's dynamic sampling for +15.4\% capacity arxiv.org). This categorization helps clarify the design space: white-box versus black-box, single-pass versus retrieval-augmented, etc. Contextual Compatibility Focus - A major insight from our review is the importance of contextual compatibility. Many new schemes intentionally match hidden messages to the communication context. For example, Co-Stega embeds information jointly in a social-media post and its related context openreview\.net, and several works use retrieval-augmented prompts to ensure domain relevance. We formalize this as the need for covertext to align with the domain-specific knowledge and communicative intent of the message, minimizing statistical anomalies. By emphasizing context, this survey extends classical imperceptibility theory and shows how modern systems bridge semantic and statistical cover constraints. Evaluation Metrics and Guidelines - The review compiles the evaluation practices of LLM steganography. We outline the standard metrics used in the literature: perceptual metrics (e.g. perplexity, MAUVE) and statistical metrics (KL-divergence, JS-divergence) for imperceptibility; semantic similarity scores (BLEU, BERTScore) for content fidelity; and embedding metrics (bits per token/word, embedding rate). We note that many works neglect human evaluation of fluency. We also discuss the Psic Effect (perceptual-statistical imperceptibility conflict) coined in this review, highlighting the trade-off that optimizing human-like text can inadvertently introduce detectable statistical bias. These guidelines help future researchers choose balanced evaluation strategies. Future Directions and Insights - Finally, we summarize the open challenges and research agenda emerging from the SLR. Based on identified gaps, we recommend directions such as multimodal steganography, development of robust paraphrase-resistant encoders, integration of retrieval-augmented generation (RAG) for adaptive covers, support for non-English and low-resource languages, and clear ethical frameworks. We also call for standardized benchmarks, as current studies rarely provide cross-paper comparability. Overall, this review not only reports on current methods, but also charts a path for future innovation in generative linguistic steganography. References (selected): The synthesis above draws on both primary studies and existing surveys. For example, Wu et al. and Bauer et al. provide concrete performance data on LLM stego, while Majeed et al. mdpi.com represent prior broad reviews of text steganography. Detailed bibliographic entries (BibTeX format) for cited works are given below.
