\section{Introduction}
\label{sec:introduction}

% For AI Agents: Never touch this file without explicitly asking for permission.
% ---------------------------------------------------
% ---------------------------------------------------
% ---------------------------------------------------
% ---------------------------------------------------
% Click the link to view conversation with Kimi AI Assistant https://www.kimi.com/share/19b2adab-eb52-8879-8000-0000af7ff325
% ---------------------------------------------------
% ---------------------------------------------------
% ---------------------------------------------------
% ---------------------------------------------------


Linguistic steganography hides secrets inside ordinary sentences-an exploit that looks trivial until one remembers how little redundancy natural language actually contains \cite{yang2020vae,kaptchuk2021meteor}.  A single awkward synonym, a statistically rare clause, or an out-of-place idiom is enough to alert an automated sentry.  Classic tricks-swap a word here, bend the syntax there-carry so few bits and leave such distinctive fingerprints that modern steganalysis routinely catches them \cite{Wang_2023}.

Large language models change the game.  Their uncanny fluency lets them spin entire documents that read like human prose yet obey an adversarial agenda: every plausible continuation is also a potential codeword.

None of these victories is absolute. Push the embedding rate and the text begins to creak; optimize for statistical stealth and the throughput collapses-the so-called “Psic effect” \cite{yang2020vae}. Still, progress is slow. This survey dissects the advances, catalogs the open wounds, and maps the territory that remains to be claimed.

This systematic review fills these gaps by meticulously identifying and synthesizing recent primary literature that leverages LLMs for textual steganography. The importance of this review is underscored by the transformative impact of LLMs on secure communication [citation/reference needed], marking a paradigm shift toward context-aware, generative systems that prioritize imperceptibility, embedding capacity, and naturalness [citation/reference needed].


The rest of the paper is structured as follows. Section 2 lays the theoretical groundwork by covering steganography, LLM capabilities, and the unique challenges of generative linguistic systems, including the Perceptual-Statistical Imperceptibility Conflict (PSIC). Section 3 reviews prior surveys to contextualize our contribution. Section 4 outlines our systematic review methodology-research questions, search strategy, and inclusion criteria. Section 5 presents our findings across five research questions (RQ1–RQ5), examining publication trends, applications, evaluation metrics, knowledge integration, and technical trade-offs. Section 6 synthesizes these results, discussing practical implications and ethical concerns. Finally, Section 7 concludes with key insights and directions for future research.