\section{Introduction}
\label{sec:introduction}

Linguistic steganography—the practice of concealing information within natural language text—has long been regarded as one of the most challenging areas of covert communication due to the low redundancy \cite{yang2020vae} \cite{kaptchuk2021meteor}, semantic rigidity, and statistical sensitivity of language. Traditional methods, such as synonym substitution, syntactic transformations, or rule-based embedding, suffer from limited capacity and detectability \cite{7925203}, making them inadequate against modern steganalysis.

The emergence of large language models (LLMs) has transformed this landscape by enabling the generation of coherent, context-aware, and statistically natural covertexts \cite{10650062}, providing a foundation for high-capacity and imperceptible covert communication. The field has seen the emergence of various LLM-based steganography paradigms: generative methods that directly create stego texts \cite{yang2020vae}\cite{DBLP:journals/corr/abs-2106-02011}\cite{ding2023discop}\cite{wu2024generative}, rewriting-based methods that rephrase existing cover texts \cite{li2023rewriting}, black-box approaches that utilize LLM user interfaces or APIs without needing access to internal model parameters \cite{wu2024generative}\cite{steinebach2024natural}, zero-shot methods that leverage in-context learning \cite{lin2024zero}, collaborative frameworks that exploit contextual relevance within social media or combine retrieval and generation strategies \cite{liao2024co}\cite{wang2023hi}, and provably secure methods that focus on mathematically rigorous security definitions \cite{kaptchuk2021meteor}\cite{ding2023discop}. However, challenges persist, including the "Psic Effect" (a trade-off between text quality and statistical imperceptibility) \cite{yang2020vae}, computational overhead, segmentation ambiguity, and the need for better understanding of contextual compatibility.

\subsection{Gap in Existing Literature}

Previous reviews on text steganography have limitations that this systematic literature review addresses. Majeed et al. (2021) \cite{math9212829} primarily focus on older techniques predating widespread LLM adoption, identifying classical approaches such as synonym replacement, spacing, and Huffman coding. The more recent review by Setiadi et al. (2025) \cite{Setiadi_Ghosal_Sahu_2025} acknowledges that linguistic steganography "has been revitalized by large language models (LLMs)" and examines AI-powered methods from post-2021, detailing techniques using GPT-2 \cite{radford2019gpt2}, GPT-3 \cite{brown2020languagemodelsfewshotlearners}, LLaMA2 \cite{touvron2023llama2openfoundation}, and Baichuan2 \cite{xiao2024baichuan2suminstructionfinetunebaichuan27b}. However, Setiadi et al. (2025) is explicitly not a systematic literature review—it is a "concise and critical examination" rather than an exhaustive survey, and it does not include all relevant papers published between 2021 and 2025.

Consequently, a notable gap persists for a comprehensive systematic literature review that: (1) employs a rigorous search and selection protocol following established SLR guidelines; (2) focuses exclusively on LLM-based approaches rather than mixing modalities; (3) systematically analyzes how context handling and contextual compatibility are addressed across methods; (4) synthesizes evaluation metrics and their inconsistent application across studies; and (5) provides a quantitative synthesis of performance metrics (capacity, imperceptibility) across the literature.

\subsection{Evaluation Standardization Challenges}

The field faces significant challenges in evaluation standardization that compound the need for systematic analysis. While core metrics like embedding rate (ER) \cite{10.1007/3-540-49380-8_21}, Kullback-Leibler divergence (KLD) \cite{1320776d-9e76-337e-a755-73010b6e4b64}, and perplexity (PPL) \cite{10.1121/1.2016299} are consistently used across studies, their inconsistent application hinders meaningful cross-method comparisons. For instance, PPL calculations vary depending on the underlying language model used (GPT-2, LLaMA, etc.) and the generated text length; KLD measurements differ based on the reference datasets (normal text) employed; and ER reporting lacks uniformity, with some studies measuring bits per token while others use bits per word. This inconsistency is compounded by the use of heterogeneous datasets across studies, ranging from IMDb \cite{10.5555/2002472.2002491} and BookCorpus \cite{Zhu_2015_ICCV} to specialized corpora like News-Commentary-v13 and HC3. Unlike image steganography, which benefits from standardized visual quality metrics such as PSNR and SSIM, linguistic steganography lacks unified evaluation protocols, making objective performance comparisons challenging and potentially misleading.

\subsection{Contributions of This Review}

This systematic literature review fills these gaps by meticulously identifying and synthesizing recent primary literature that leverages LLMs for textual steganography, particularly from the last two years when LLMs like GPT-3/4 and open models became widely available. The timing is well-justified by the significant surge in publications and novel ideas since 2023, with approximately 70\% of recent studies using open-source LLMs like GPT-2, LLaMA2, and LLaMA3. The specific contributions of this review include:

\begin{itemize}
	\item \textbf{Systematic synthesis of LLM-based steganography}: A comprehensive analysis of 18 primary studies and 14 additional papers, organized around six research questions covering the state of literature, applications, evaluation metrics, knowledge integration, limitations, and future directions.
	\item \textbf{Taxonomy of context handling}: A systematic classification of how methods address contextual compatibility, distinguishing between explicit, implicit, and no-context approaches, and analyzing how context representation (text, pretext, graph, vector) affects performance.
	\item \textbf{Quantitative synthesis of performance metrics}: A systematic compilation and comparison of embedding capacity (bits per token/word), imperceptibility metrics (PPL, KLD, anti-steganalysis accuracy), and their trade-offs across different method categories (white-box, black-box, hybrid).
	\item \textbf{Mapping of applications and requirements}: A comprehensive analysis of application domains (covert communication, watermarking, fingerprinting, adversarial attacks) and their specific capacity, security, and imperceptibility requirements.
	\item \textbf{Identification of open problems and future directions}: A synthesis of limitations, trade-offs, and research gaps that guides future work in provable security, multimodal steganography, ethical considerations, and evaluation standardization.
\end{itemize}

\subsection{Paper Structure}

The rest of this paper follows a standard systematic literature review structure. Section 2 provides background on steganography and LLMs, defining key concepts such as imperceptibility dimensions (perceptual, statistical, cognitive), channel entropy, perfect samplers, and contextual compatibility—the core organizing principle for this review. Section 3 establishes the design space for LLM-based steganography, organizing methods along axes of access mode (white-box/black-box/hybrid), generation style, and context usage, and positioning key methods within this space. Section 4 reviews related surveys and literature reviews, articulating how this systematic review extends and differs from existing work. Section 5 details the research method, explicitly listing the six research questions and describing the systematic search, selection, and data extraction protocol. Section 6 reports the results organized by research question: Section~\ref{subsec:rq1} analyzes the state of published literature and publication trends; Section~\ref{subsec:rq2} maps application domains and their requirements; Section~\ref{subsec:rq3} synthesizes evaluation metrics and identifies standardization challenges; Section~\ref{subsec:rq4} analyzes how external knowledge sources are integrated for context handling; and Section~\ref{subsec:rq5} synthesizes limitations and trade-offs. Section 7 synthesizes the main findings and discusses trends, limitations, and implications. Finally, Section 8 concludes by outlining open problems and future research directions.