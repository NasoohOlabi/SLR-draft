\section{Introduction}
\label{sec:introduction}

This review explores how large language models (LLMs) are transforming linguistic steganography, the practice of hiding messages in text. We focus on the unique challenges and advances in using LLMs for secure, imperceptible, and high-capacity covert communication.

\subsection{Overview of Information Security and Concealment Systems}
Information security systems include \textbf{encryption}, \textbf{privacy}, and \textbf{concealment} (steganography).

\subsubsection{Encryption Systems and Privacy Systems}
These protect content but reveal that secret communication is happening, which can attract attention.

\subsubsection{Concealment Systems (Steganography)}
Steganography hides the existence of information by embedding it in ordinary carriers (e.g., text, images). The fundamental goal is to achieve \textbf{imperceptibility}. Text is a challenging carrier due to its low redundancy and strict semantics.

\subsection{Introduction to Steganography}
Steganography is often explained by the ``Prisoners' Problem'' \cite{simmons1984prisoners}, where Alice and Bob must communicate secretly under surveillance. The goal is to embed messages so they are undetectable to an observer.

Steganography methods include \textbf{carrier selection}, \textbf{carrier modification}, and \textbf{carrier generation} \cite{fridrich2009steganography}.
\begin{itemize}
    \item \textbf{Carrier modification:} Hide information in existing text with minimal changes.
    \item \textbf{Carrier generation:} Generate new text that encodes information, allowing higher capacity but requiring naturalness.
\end{itemize}

\subsection{The Significance of Linguistic Steganography}
Linguistic steganography enables covert communication, especially where encryption is suspicious. Text is a robust, ubiquitous carrier but presents challenges in balancing imperceptibility and capacity. Advances in deep learning and LLMs improve text quality and security, while related fields like watermarking focus on tracing content origin.



\subsection{Key Terminology and Definitions}
\label{sec:terminology}
To ensure accessibility for readers from diverse academic backgrounds, we provide formal definitions of critical technical terms used throughout this review:

\begin{itemize}
    \item \textbf{Perceptual Imperceptibility}: The property that steganographic text appears natural and indistinguishable from normal text to human observers, maintaining linguistic fluency and contextual appropriateness.
    
    \item \textbf{Statistical Imperceptibility}: The property that the statistical characteristics of steganographic text match those of the cover medium, making it undetectable by automated statistical analysis.
    
    \item \textbf{Cognitive Imperceptibility}: The property that the semantic content and contextual coherence of steganographic text remain consistent with expected communication patterns and domain-specific knowledge \cite{ding2023context}.
    
    \item \textbf{Channel Entropy}: A measure of uncertainty or randomness in the communication medium that determines the theoretical capacity for information hiding. Higher entropy allows for greater embedding capacity.
    
    \item \textbf{Perfect Samplers}: Algorithms that can generate samples from a probability distribution with perfect accuracy, ensuring no statistical deviation from the target distributionâ€”a requirement for provably secure steganography.
    
    \item \textbf{Explicit Data Distributions}: Clearly defined mathematical representations of the probability distributions governing the cover medium, enabling precise security analysis and theoretical guarantees.
    
    \item \textbf{Large Language Models (LLMs)}: A large language model (LLM) is a transformer-based model trained on massive text datasets, often with billions of parameters, enabling it to generate and understand human language across a wide variety of tasks \cite{shanahan2024talking}.
    
    \item \textbf{Hallucinations (in LLMs)}: Instances where language models generate plausible-sounding but factually incorrect, nonsensical, or contextually inappropriate content due to limitations in training data or model architecture.
    
    \item \textbf{Psic Effect} \cite{yang2020vae}: The Perceptual-Statistical Imperceptibility Conflict Effect, representing the fundamental trade-off where optimizations for perceptual quality may compromise statistical security and vice versa.
\end{itemize}

\subsection{Scope of the Review}
This review covers LLM-based linguistic steganography, focusing on methods, evaluation, challenges, and future directions.