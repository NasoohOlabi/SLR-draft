\section{Research Method}\label{sec:design}


This study was undertaken as a systematic mapping review using the guidelines presented in
Petersen et al. \cite{slr_guidelines}. The goal of this review is to identify, categorize, and analyze existing literature
published between 2018 and 2025 and use syntactic and semantics aspects to represent context handling in linguistic steganographic methods.

\subsection{Planning}

In this section, we deﬁne our research questions, the search strategy we use, and the inclusion
and exclusion criteria considered to ﬁlter the results.

\subsubsection{Research Questions}
This systematic literature review is guided by six research questions, aiming to comprehensively map the landscape of steganographic techniques leveraging large language models (LLMs). The questions explore the current state of published literature, applications where these techniques are being explored, and the metrics and evaluation methods used to assess their performance, with a focus on capacity, security, and contextual compatibility. Furthermore, the review investigates how external knowledge sources are integrated to enhance capacity or contextual relevance, the limitations and trade-offs associated with current techniques, and potential future research directions considering emerging trends and identified gaps.

\subsubsection{Search Strategies}
The initial literature search employed a specific query string: `(steganography or watermark or "Information Hiding") and ("Large Language Model" or LLM or BERT or LAMA or GPT)`. This query was executed across several digital libraries, including ACM Digital Library, IEEE Digital Library, Science@Direct, Scopus, and Springer Link, to ensure broad coverage. To complement this automated search and identify additional relevant studies, a snowballing technique was also applied. This involved examining the reference lists of included studies. While snowballing primarily yielded older steganographic techniques not explicitly mentioning LLMs, these papers often utilized similar methodological approaches to contemporary LLM-based steganography, providing valuable contextual information.

\subsubsection{Inclusion and Exclusion Criteria}
To ensure the selection of high-quality and relevant studies, a rigorous set of inclusion and exclusion criteria was established. Studies were included if they provided full-text access, were published in English, appeared in peer-reviewed journals, conferences, or workshops, and were published from 2018 onwards to focus on recent advancements in LLMs. Furthermore, included studies had to directly address steganography, watermarking, or information hiding techniques that utilize or are significantly impacted by LLMs, BERT, LAMA, or GPT architectures. The research types considered were empirical studies, surveys, reviews, and theoretical contributions. Conversely, studies were excluded if they were duplicates (with the most complete or recent version retained), incomplete or abstract-only, irrelevant to steganography with LLMs, non-English publications, or non-peer-reviewed sources such as preprints, dissertations, theses, books, and book chapters (unless they were extended versions of peer-reviewed conference papers).

\subsection{Conducting the Search}
The initial automated search across the selected digital libraries yielded a total of 1043 candidate papers. The distribution by source was: ACM Digital Library (346), IEEE Digital Library (61), Science@Direct (209), Scopus (151), and Springer Link (276). Following this, a rigorous process of duplicate removal was undertaken using both automated tools and manual verification, resulting in 989 unique papers. These papers then underwent a multi-stage filtering process based on their titles, abstracts, and full texts, guided by the predefined inclusion and exclusion criteria. After title and abstract filtering, 58 papers remained. Of these, 18 were accepted with readily available PDFs, while 14 were pending PDF acquisition at the time of analysis.

\subsection{Data Extraction and Classification}
A comprehensive Data Extraction Form (DEF) was developed to systematically collect relevant information from each primary study. The DEF was designed to capture key details essential for addressing the research questions, including the paper's title, type (Steganography or Watermarking), and descriptions of the model input and output formats and their key characteristics. It also captured a three-term categorical description of the approach, the specific LLM used (if applicable), and a list of all datasets employed, including their sizes. The DEF further included fields for identifying the main strengths and weaknesses of the approach or model, the evaluation metrics and steganalysis models used, and the best numerical results for each reported metric. Information on code availability and links was also collected. Key aspects of the embedding process were described concisely, focusing on high-level pipeline descriptions rather than method names (e.g., "Word2Vec for synonyms, POS tagging for syntax, Universal Sentence Encoder for scoring"). To assess contextual relevance, the form captured whether the method was "Explicit," "Implicit," or "No" in its context awareness, defined as the channel where the resultant stego-text is sent. This included a categorical context keyword (e.g., "Social Media," "Formal Document"), an explanation of how context is represented (e.g., "Text," "Pretext," "Graph," "Vector"), and a detailed description of how context is utilized within the method. Following data extraction, studies were classified based on predefined categories derived from our research questions to group similar studies and identify trends, patterns, and gaps in the existing literature. The results of this data synthesis are presented using tables, figures (such as the Sunburst Chart of LLM Approaches shown in Figure \ref{fig:sunburst_chart}), and descriptive statistics to summarize key findings, including publication trends and the distribution of studies across different categories and approaches. Each research question is then addressed individually, with a detailed discussion of the synthesized data, interpretation of findings, and identification of future research directions.

% \subsection{Threats to Validity}
% While this systematic literature review (SLR) adheres to established guidelines such as PRISMA to ensure methodological rigor, several potential threats to validity must be acknowledged. These threats primarily relate to the comprehensiveness of the literature search, selection biases, and practical constraints in data acquisition. The search strategy may introduce publication and selection biases, as it was limited to English-language publications from 2018 onward, potentially excluding relevant non-English studies or foundational pre-2018 works on linguistic steganography that predate widespread LLM adoption. Although LLMs emerged prominently around 2018 with models such as BERT, this cutoff might overlook influential earlier contributions that inform current techniques. Additionally, the selected databases provide broad coverage but may miss papers in other repositories, and the search terms, while comprehensive, could overlook synonyms or emerging variants despite efforts to include related phrases such as "Information Hiding." Biases in study selection and quality assessment could also affect the review's internal validity; the inclusion criteria focused on peer-reviewed sources, which enhances reliability but may introduce publication bias by favoring positive or novel results. No formal risk-of-bias tool (e.g., ROBIS) was applied beyond basic relevance checks, potentially allowing lower-quality studies to influence findings. To mitigate this, multi-stage filtering with title, abstract, and full-text reviews was employed, and snowballing was used to identify additional references, though it primarily yielded older non-LLM works. Practical limitations also posed threats to completeness, as 14 papers remained pending PDF acquisition at the time of analysis, which could lead to incomplete coverage if these contain critical insights. This issue was addressed by prioritizing accessible studies and planning follow-up acquisition, but it highlights retrieval challenges in SLR processes. Overall, these threats were minimized through transparent documentation of the methodology, adherence to PRISMA reporting standards, and supplementary snowballing. Future updates to this review could expand database coverage and incorporate automated tools for bias assessment to further enhance validity.


\begin{figure*}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{sunburst_chart.pdf}
    \caption{Sunburst Chart of LLM Approaches}
    \Description{A sunburst chart displaying the hierarchical breakdown of Large Language Model approaches used in steganography research. The chart shows different categories and subcategories of LLM-based steganographic techniques, with each segment representing the relative proportion of different methodological approaches found in the literature review.}
    \label{fig:sunburst_chart}
\end{figure*} 


% \subsection{Presentation of Results}

% The results of the data synthesis are presented in a structured manner, often utilizing tables, figures, and descriptive statistics to summarize key findings. This includes an overview of publication trends, distribution of studies across different categories, and the prevalence of various approaches and techniques.

% \subsection{Discussion in Relation to Research Questions}

% Each research question is addressed individually, with a detailed discussion of the synthesized data. This involves interpreting the findings, highlighting significant observations, and drawing conclusions based on the evidence gathered from the primary studies. The discussion also identifies areas where further research is needed and potential future directions.