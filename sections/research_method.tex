\section{Research Method}\label{sec:design}


This study was undertaken as a systematic mapping review using the guidelines presented in
Petersen et al. \cite{slr_guidelines}. The goal of this review is to identify, categorize, and analyze existing literature
published between 2018 and 2025 and use syntactic and semantics aspects to represent context handling in linguistic steganographic methods.

\subsection{Planning}

In this section, we deÔ¨Åne our research questions, the search strategy we use, and the inclusion
and exclusion criteria considered to filter the results.

\subsubsection{Research Questions}
This systematic literature review is guided by six research questions, aiming to comprehensively map the landscape of steganographic techniques leveraging large language models (LLMs). The questions explore the current state of published literature, applications where these techniques are being explored, and the metrics and evaluation methods used to assess their performance, with a focus on capacity, security, and contextual compatibility. Furthermore, the review investigates how external knowledge sources are integrated to enhance capacity or contextual relevance, the limitations and trade-offs associated with current techniques, and potential future research directions considering emerging trends and identified gaps.

\subsubsection{Search Strategies}
The initial literature search employed a specific query string: `(steganography or watermark or "Information Hiding") and ("Large Language Model" or LLM or BERT or LAMA or GPT)`. This query was executed across several digital libraries, including ACM Digital Library, IEEE Digital Library, Science@Direct, Scopus, and Springer Link, to ensure broad coverage. To complement this automated search and identify additional relevant studies, a snowballing technique was also applied. This involved examining the reference lists of included studies. While snowballing primarily yielded older steganographic techniques not explicitly mentioning LLMs, these papers often utilized similar methodological approaches to contemporary LLM-based steganography, providing valuable contextual information.


\subsubsection{Inclusion and Exclusion Criteria}
To ensure the selection of high-quality and relevant studies, the following criteria were applied.

\textbf{Inclusion Criteria}
Studies were included if they:

\begin{enumerate}[label=IC\arabic*:]
    \item Provided full-text access.
    \item Were published in English from 2018 onwards.
    \item Appeared in peer-reviewed journals, conferences, or workshops.
    \item Directly addressed steganography, watermarking, or information hiding techniques involving or significantly impacted by LLMs, BERT, LAMA, or GPT architectures.
    \item Represented empirical studies, surveys, reviews, or theoretical contributions.
\end{enumerate}


\textbf{Exclusion Criteria}
Studies were excluded if they:

\begin{enumerate}[label=IC\arabic*:]
    \item Were duplicates (retaining the most complete or recent version).
    \item Were incomplete, abstract-only, or irrelevant to steganography with LLMs.
    \item Were non-English publications.
    \item Came from non-peer-reviewed sources (e.g., preprints, dissertations, theses, books, book chapters), unless extended from peer-reviewed conference papers.
\end{enumerate}



\subsection{Conducting the Search}
The initial automated search across the selected digital libraries yielded a total of 1043 candidate papers. The distribution by source was: ACM Digital Library (346), IEEE Digital Library (61), Science@Direct (209), Scopus (151), and Springer Link (276). Duplicated papers were automatically eliminated using Parsifal tool \footnote{\href{https://parsif.al}{https://parsif.al}}. After removing all duplicates, 1,573 papers remained. Following this the papers underwent a multi-stage filtering process based on their titles, abstracts, and full texts, guided by the predefined inclusion and exclusion criteria. After title and abstract filtering, 58 papers remained. Of these, 18 were accepted with readily available PDFs, while 14 were pending PDF acquisition at the time of analysis.

\subsection{Data Extraction and Classification}
A Data Extraction Form (DEF) was developed to systematically collect data from each primary study to address our research questions. The form is designed in a table format consisting of the following types of information:

\begin{itemize}
    \item Bibliometric Information: paper title, type (Steganography or Watermarking), author(s), publication year, and publication venue.
    \item Model Details: input and output formats, key characteristics, approach classification (three-term categorical), specific LLM used (if applicable), embedding process description, and code availability.
    \item Datasets: all datasets employed, including their sizes.
    \item Context Awareness: whether the method is "Explicit," "Implicit," or "No," the context keyword (e.g., "Social Media," "Formal Document"), how context is represented (e.g., "Text," "Pretext," "Graph," "Vector"), and how it is utilized in the method.
    \item Evaluation Details: evaluation metrics, steganalysis models used, and the best numerical results for each reported metric.
    \item Strengths and Limitations: main strengths and weaknesses of the approach or model.
\end{itemize}

Following data extraction, studies were classified based on predefined categories derived from the research questions to identify trends, patterns, and gaps in the literature. The results are summarized using tables, figures  \ref{fig:sunburst_chart}), and descriptive statistics. Each research question is addressed individually with interpretation of findings and identification of future research directions.

% \subsection{Threats to Validity}
% While this systematic literature review (SLR) adheres to established guidelines such as PRISMA to ensure methodological rigor, several potential threats to validity must be acknowledged. These threats primarily relate to the comprehensiveness of the literature search, selection biases, and practical constraints in data acquisition. The search strategy may introduce publication and selection biases, as it was limited to English-language publications from 2018 onward, potentially excluding relevant non-English studies or foundational pre-2018 works on linguistic steganography that predate widespread LLM adoption. Although LLMs emerged prominently around 2018 with models such as BERT, this cutoff might overlook influential earlier contributions that inform current techniques. Additionally, the selected databases provide broad coverage but may miss papers in other repositories, and the search terms, while comprehensive, could overlook synonyms or emerging variants despite efforts to include related phrases such as "Information Hiding." Biases in study selection and quality assessment could also affect the review's internal validity; the inclusion criteria focused on peer-reviewed sources, which enhances reliability but may introduce publication bias by favoring positive or novel results. No formal risk-of-bias tool (e.g., ROBIS) was applied beyond basic relevance checks, potentially allowing lower-quality studies to influence findings. To mitigate this, multi-stage filtering with title, abstract, and full-text reviews was employed, and snowballing was used to identify additional references, though it primarily yielded older non-LLM works. Practical limitations also posed threats to completeness, as 14 papers remained pending PDF acquisition at the time of analysis, which could lead to incomplete coverage if these contain critical insights. This issue was addressed by prioritizing accessible studies and planning follow-up acquisition, but it highlights retrieval challenges in SLR processes. Overall, these threats were minimized through transparent documentation of the methodology, adherence to PRISMA reporting standards, and supplementary snowballing. Future updates to this review could expand database coverage and incorporate automated tools for bias assessment to further enhance validity.




% \subsection{Presentation of Results}

% The results of the data synthesis are presented in a structured manner, often utilizing tables, figures, and descriptive statistics to summarize key findings. This includes an overview of publication trends, distribution of studies across different categories, and the prevalence of various approaches and techniques.

% \subsection{Discussion in Relation to Research Questions}

% Each research question is addressed individually, with a detailed discussion of the synthesized data. This involves interpreting the findings, highlighting significant observations, and drawing conclusions based on the evidence gathered from the primary studies. The discussion also identifies areas where further research is needed and potential future directions.