\documentclass[manuscript,screen,review]{sections/acmart} % Preprint format
\setcitestyle{acmauthoryear} % Replace \citestyle with ACM-recommended command
\settopmatter{printacmref=false} % Removes citation information below abstract
\renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in first column
\pagestyle{plain} % removes running headers
\usepackage{tabularx}
\usepackage{longtable}
\usepackage{pifont} % used for \todo symbol
\newcommand{\todo}[1]{\textcolor{blue}{#1}}

\usepackage{hyperref}
\usepackage{float}
% \usepackage{accsupp} % For accessibility support

% % Suppress false positive accessibility warnings if all descriptions are present
% \makeatletter
% \renewcommand{\@acmart@checkdesc}{}
% \makeatother

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08emT\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
    
% Preprint metadata
\copyrightyear{2025}
\acmYear{2025}
\acmMonth{8}
\setcopyright{rightsretained}

% Preprint information
\acmSubmissionID{Preprint-2025-08}

%
% The majority of ACM publications use numbered citations and references. If you are preparing content for an event
% sponsored by ACM SIGGRAPH, you must use the "author year" style of citations and references. Uncommenting
% the next command will enable that style.
%\citestyle{acmauthoryear}

% The first command in your LaTeX source must be the \documentclass command.
%
% end of the preamble, start of the body of the document source.
\begin{document}

% These commands have SAMPLE values in them; it is your responsibility as an author to replace
%
% The "title" command has an optional parameter, allowing the author to define a "short title" to be used in page headers.
\title{Enhancing Contextual Compatibility of Textual Steganography Systems Based on Large Language Models}

%
% The "author" command and its associated commands are used to define the authors and their affiliations.
% Of note is the shared affiliation of the first two authors, and the "authornote" and "authornotemark" commands
% used to denote shared contribution to the research.

% \author{Ben Trovato}
% \authornote{Both authors contributed equally to this research.}
% \email{trovato@corporation.com}
% \orcid{1234-5678-9012}
% \author{G.K.M. Tobin}
% \authornotemark[1]
% \email{webmaster@marysville-ohio.com}
% \affiliation{%
%   \institution{Institute for Clarity in Documentation}
%   \streetaddress{P.O. Box 1212}
%   \city{Dublin}
%   \state{Ohio}
%   \postcode{43017-6221}
% }

\author{Nasouh AlOlabi}
\affiliation{%
  \institution{Higher Institute for Applied Sciences and Technology}
  \city{Damascus}
  \country{Syria}}
% \email{nasouhalolabi@gmail.com}

\author{Riad Sonbol}
\affiliation{%
  \institution{Higher Institute for Applied Sciences and Technology}
  \city{Damascus}
  \country{Syria}}
% \email{rsimbol@sharjah.ac.ae}

 
%
% By default, the full list of authors will be used in the page headers. Often, this list is too long, and will overlap
% other information printed in the page headers. This command allows the author to define a more concise list
% of authors' names for this purpose.
%\renewcommand{\shortauthors}{Verdecchia, et al.}

%
% The abstract is a short summary of the work to be presented in the article.
\begin{abstract}
This systematic literature review examines the transformative impact of Large Language Models (LLMs) on linguistic steganography. Through comprehensive analysis of 18 primary studies and 14 additional papers, the research demonstrates that LLM-based approaches significantly enhance imperceptibility (achieving PPL scores of 3-8 for white-box methods), embedding capacity (up to 5.98 bits per token), and naturalness in cover text generation, addressing traditional limitations of low embedding capacity and cognitive imperceptibility. The findings reveal a paradigm shift towards context-aware steganographic systems that leverage domain-specific knowledge and communicative context to achieve both perceptual and statistical imperceptibility. The review establishes that understanding contextual compatibility and domain correlations is crucial for developing more sophisticated, robust, and secure covert communication systems, paving the way for future advancements in generative text steganography.
\end{abstract}

%
% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
% Please copy and paste the code instead of the example below.
%
% \begin{CCSXML}
% <ccs2012>
%  <concept>
%   <concept_id>10010520.10010553.10010562</concept_id>
%   <concept_desc>Computer systems organization~Embedded systems</concept_desc>
%   <concept_significance>500</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>10010520.10010575.10010755</concept_id>
%   <concept_desc>Computer systems organization~Redundancy</concept_desc>
%   <concept_significance>300</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>10010520.10010553.10010554</concept_id>
%   <concept_desc>Computer systems organization~Robotics</concept_desc>
%   <concept_significance>100</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>10003033.10003083.10003095</concept_id>
%   <concept_desc>Networks~Network reliability</concept_desc>
%   <concept_significance>100</concept_significance>
%  </concept>
% </ccs2012>
% \end{CCSXML}

% \ccsdesc[500]{Computer systems organization~Embedded systems}
% \ccsdesc[300]{Computer systems organization~Redundancy}
% \ccsdesc{Computer systems organization~Robotics}
% \ccsdesc[100]{Networks~Network reliability}

%
% Keywords. The author(s) should pick words that accurately describe the work being
% presented. Separate the keywords with commas.
\keywords{Systematic Literature Review, Linguistic Steganography, Large Language Models, LLMs, Natural Language Processing, NLP, Black-box Steganography, Context Retrieval, Generative Text Steganography, Imperceptibility}

%
% A "teaser" image appears between the author and affiliation information and the body 
% of the document, and typically spans the page. 

%
% This command processes the author and affiliation and title information and builds
% the first part of the formatted document.
\maketitle

\noindent\textbf{Preprint Notice:} This is a preprint version of our systematic literature review, last updated on August 12, 2025. The work is currently under review for publication.

%\vspace{10pt}
% IMPORTANT: Do not change or add any headers below this line.
\input{sections/introduction.tex}
\input{sections/background.tex}
\input{sections/llm_approaches.tex} % This will be '3. Steganography and Large Language Models'
\input{sections/related_reviews.tex}
\input{sections/research_method.tex} 
\input{sections/results_and_discussion.tex} % Replaces results.tex and discussion.tex
\input{sections/main_findings.tex} % New section with main findings
\input{sections/conclusion.tex}

\bibliographystyle{ACM-Reference-Format}
\bibliography{references/bibliography}

% 
% If your work has an appendix, this is the place to put it.
%\appendix


\end{document}
