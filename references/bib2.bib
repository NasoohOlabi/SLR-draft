@article{Touvron_2023,
  title   = {LLaMA: Open and Efficient Foundation Language Models},
  year    = {2023},
  author  = {Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and M. Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aur'elien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
  doi     = {null},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {null},
  journal = {arXiv.org}
}
@article{Touvron_2023,
  title   = {Llama 2: Open Foundation and Fine-Tuned Chat Models},
  year    = {2023},
  author  = {Hugo Touvron and Louis Martin and Kevin R. Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Niko-lay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and D. Bikel and Lukas Blecher and Cris-tian Cantón Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and J. Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and A. Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel M. Kloumann and A. Korenev and Punit Singh Koura and M. Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and J. Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and R. Subramanian and Xia Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zhengxu Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and M. Kambadur and Sharan Narang and Aur'elien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
  doi     = {null},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {null},
  journal = {arXiv.org}
}
@article{Yang_2023,
  title   = {Baichuan 2: Open Large-scale Language Models},
  year    = {2023},
  author  = {A. Y. Yang and Bin Xiao and Bingning Wang and Borong Zhang and Ce Bian and Chao Yin and Chenxu Lv and Da Pan and Dian Wang and Yan Dong and Fan Yang and Fei Deng and Rui Wang and Ling Feng and Guoxiang Ai and Guangjiong Dong and Hang Zhao and Huiling Xu and Huiyong Sun and Hongda Zhang and Hui Liu and Jiaming Ji and Jin Xie and Jianrong Dai and Kai‐Tai Fang and Liyun Su and Linqi Song and Lifeng Liu and Liyun Ru and Li Ma and Mang Wang and Mickel Liu and Meng-Ying Lin and Nan Nie and Peidong Guo and Ruiyang Sun and Tao Zhang and Tianpeng Li and Tianyu Li and Cheng Wei and Wei-Peng Chen and Xiangrong Zeng and Xiaochuan Wang and Xiaoxi Chen and X.Y. Men and Xin Yu and Xuehai Pan and Yanjun Shen and Yiding Wang and Yiyu Li and Y. Jiang and Yuchen Gao and Yupeng Zhang and Zheng Zhou and Zhen Wu},
  doi     = {10.48550/arxiv.2309.10305},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {4386942538},
  journal = {arXiv.org}
}
@article{Li_2016,
  title   = {A Diversity-Promoting Objective Function for Neural Conversation Models},
  year    = {2016},
  author  = {Jiwei Li and Jiwei Li and Michel Galley and Michel Galley and Chris Brockett and Chris Brockett and Jianfeng Gao and Jianfeng Gao and Bill Dolan and Bill Dolan},
  doi     = {10.18653/v1/n16-1014},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {2963206148},
  journal = {North American Chapter of the Association for Computational Linguistics}
}
@article{Devlin_2019,
  title   = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  year    = {2019},
  author  = {Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
  doi     = {10.18653/v1/n19-1423},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {2951055169},
  journal = {North American Chapter of the Association for Computational Linguistics}
}
@article{Yang_2020,
  title   = {VAE-Stega: Linguistic Steganography Based on Variational Auto-Encoder},
  year    = {2020},
  author  = {Zhongliang Yang and Zhongliang Yang and Siyu Zhang and Si-Yu Zhang and Yuting Hu and Yuting Hu and Yuting Hu and Zhiwen Hu and Zhiwen Hu and Zhiwen Hu and Yudong Huang and Yongfeng Huang and Yongfeng Huang},
  doi     = {10.1109/tifs.2020.3023279},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {3085519426},
  journal = {IEEE Transactions on Information Forensics and Security}
}
@article{Zheng_2022,
  title   = {General Framework for Reversible Data Hiding in Texts Based on Masked Language Modeling},
  year    = {2022},
  author  = {Xiaoyan Zheng and Yurun Fang and Hanzhou Wu},
  doi     = {10.1109/mmsp55362.2022.9948940},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {4313056719},
  journal = {IEEE International Workshop on Multimedia Signal Processing}
}
@article{Ding_2023,
  title   = {Joint Linguistic Steganography With BERT Masked Language Model and Graph Attention Network},
  year    = {2023},
  author  = {Changhao Ding and Zhangjie Fu and Qi Yu and Fan Wang and Xianyi Chen},
  doi     = {10.1109/tcds.2023.3296413},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {4384787020},
  journal = {IEEE Transactions on Cognitive and Developmental Systems}
}
@article{Li_2023,
  title   = {Rewriting-Stego: Generating Natural and Controllable Steganographic Text with Pre-trained Language Model},
  year    = {2023},
  author  = {Fanxiao Li and Sixing Wu and Jiong Yu and Shuoxin Wang and Bingbing Song and Renyang Liu and Haoseng Lai and Wei Zhou},
  doi     = {10.1007/978-3-031-30637-2_41},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {4365794970},
  journal = {International Conference on Database Systems for Advanced Applications}
}
@article{Qiang_2023,
  title   = {Natural language watermarking via paraphraser-based lexical substitution},
  year    = {2023},
  author  = {Jipeng Qiang and Shiyu Zhu and Yun Li and Yi Zhu and Yunhao Yuan and Xindong Wu},
  doi     = {10.1016/j.artint.2023.103859},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {4319831446},
  journal = {Artificial Intelligence}
}
@article{Yi_2022,
  title   = {ALiSa: Acrostic Linguistic Steganography Based on BERT and Gibbs Sampling},
  year    = {2022},
  author  = {Biao Yi and YI Biao and Hanzhou Wu and Hanzhou Wu and Guorui Feng and Guorui Feng and Xinpeng Zhang and Xinpeng Zhang},
  doi     = {10.1109/lsp.2022.3152126},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {4213325746},
  journal = {IEEE Signal Processing Letters}
}
@article{Qi_2024,
  title   = {Provably Secure Disambiguating Neural Linguistic Steganography},
  year    = {2024},
  author  = {Yuang Qi and Kejiang Chen and Kai Zeng and Weiming Zhang and Neng H. Yu},
  doi     = {10.1109/tdsc.2024.3519322},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {null},
  journal = {IEEE Transactions on Dependable and Secure Computing}
}
@article{Wu_2024,
  title   = {Generative Text Steganography with Large Language Model},
  year    = {2024},
  author  = {Jiaxuan Wu and Zhengxian Wu and Yiming Xue and Juan Wen and Wanli Peng},
  doi     = {10.48550/arxiv.2404.10229},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {null},
  journal = {ACM Multimedia}
}
@article{Radford_2019,
  title   = {Language Models are Unsupervised Multitask Learners},
  year    = {2019},
  author  = {Alec Radford and Jeff Wu and R. Child and D. Luan and Dario Amodei and I. Sutskever},
  doi     = {null},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {2955855238},
  journal = {null}
}
@article{Brown_2020,
  title   = {Language Models are Few-Shot Learners},
  year    = {2020},
  author  = {T. B. Brown and Tom B. Brown and Benjamin Mann and Benjamin Mann and Nick Ryder and Nick Ryder and Nick Ryder and Melanie Subbiah and Melanie Subbiah and Jared Kaplan and Jared Kaplan and Prafulla Dhariwal and Prafulla Dhariwal and Arvind Neelakantan and Arvind Neelakantan and Pranav Shyam and Pranav Shyam and Pranav Shyam and Girish Sastry and Girish Sastry and Girish Sastry and Amanda Askell and Amanda Askell and Sandhini Agarwal and Sandhini Agarwal and Ariel Herbert-Voss and Ariel Herbert-Voss and Gretchen Krueger and Gretchen Krueger and Tom Henighan and Thomas Henighan and Rewon Child and Rewon Child and A. Ramesh and Aditya Ramesh and Aditya Ramesh and Daniel M. Ziegler and Daniel M. Ziegler and Daniel M. Ziegler and Jeffrey Wu and Jeffrey Wu and Clemens Winter and Clemens Winter and Christopher Hesse and Christopher Hesse and Mark Chen and Mark Chen and Eric J. Sigler and Eric Sigler and Mateusz Litwin and Mateusz Litwin and Scott Gray and Scott Gray and Benjamin Chess and Benjamin Chess and Jack Clark and Jack Clark and Christopher Berner and Christopher Berner and Sam McCandlish and Samuel McCandlish and Alec Radford and Alec Radford and Ilya Sutskever and Ilya Sutskever and Dario Amodei and Dario Amodei},
  doi     = {null},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {3030163527},
  journal = {Neural Information Processing Systems}
}
@article{Wang_2022,
  title   = {Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks},
  year    = {2022},
  author  = {Yizhong Wang and Swaroop Mishra and Pegah Alipoormolabashi and Yeganeh Kordi and Amirreza Mirzaei and Ajit Kumar Naik and Arjun Ashok and Arut Selvan Dhanasekaran and Anjana Arunkumar and David Stap and Eshaan Pathak and Giannis Karamanolakis and H. Y. Lai and Ishan Purohit and Ishani Mondal and J. Anderson and Kirby Kuznia and Krima Doshi and Kuntal Kumar Pal and Maitreya Patel and Mehrad Moradshahi and Mihir Parmar and Mirali Purohit and Neeraj Varshney and Phani Rohitha Kaza and Pulkit Verma and Ravsehaj Singh Puri and Rushang Karia and Savan Doshi and Shailaja Keyur Sampat and Siddhartha Mishra and Sujan Reddy A and Sumanta Patro and Tanay Dixit and Xudong Shen},
  doi     = {10.18653/v1/2022.emnlp-main.340},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {4385572845},
  journal = {Conference on Empirical Methods in Natural Language Processing}
}
@article{Zhang_2023,
  title   = {Aligning Instruction Tasks Unlocks Large Language Models as Zero-Shot
             Relation Extractors},
  year    = {2023},
  author  = {Kai Zhang and Bernal Jiménez Gutiérrez and Yu Su},
  doi     = {10.48550/arxiv.2305.11159},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {4377164385},
  journal = {Annual Meeting of the Association for Computational Linguistics}
}
@article{Simmons_1984,
  title   = {The Prisoners’ Problem and the Subliminal Channel},
  year    = {1984},
  author  = {Gustavus J. Simmons and Gustavus J. Simmons and Gustavus J. Simmons},
  doi     = {10.1007/978-1-4684-4730-9_5},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {1878907771},
  journal = {Annual International Cryptology Conference}
}
@article{Fridrich_2009,
  title   = {Steganography in Digital Media: Principles,
             Algorithms,
             and Applications},
  year    = {2009},
  author  = {Jessica Fridrich and Jessica Fridrich},
  doi     = {10.1017/cbo9781139192903.001},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {1482218439},
  journal = {null}
}
@article{Pillutla_2021,
  title   = {MAUVE: Measuring the Gap Between Neural Text and Human Text using Divergence Frontiers},
  year    = {2021},
  author  = {Krishna Pillutla and Swabha Swayamdipta and Rowan Zellers and John Thickstun and S. Welleck and Yejin Choi and Zaïd Harchaoui},
  doi     = {null},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {null},
  journal = {Neural Information Processing Systems}
}
@article{Holtzman_2019,
  title    = {The Curious Case of Neural Text Degeneration},
  year     = {2019},
  author   = {Ari Holtzman and Ari Holtzman and Jan Buys and Jan Buys and Li Du and Maxwell Forbes and Leo Du and Maxwell Forbes and Yejin Choi and Yejin Choi},
  doi      = {null},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {2938704169},
  journal  = {arXiv: Computation and Language},
  abstract = {Despite considerable advancements with deep neural language models,
              the enigma of neural text degeneration persists when these models are tested as text generators. The counter-intuitive empirical observation is that even though the use of likelihood as training objective leads to high quality models for a broad range of language understanding tasks,
              using likelihood as a decoding objective leads to text that is bland and strangely repetitive. 
              In this paper,
              we reveal surprising distributional differences between human text and machine text. In addition,
              we find that decoding strategies alone can dramatically effect the quality of machine text,
              even when generated from exactly the same neural language model. 
              Our findings motivate Nucleus Sampling,
              a simple but effective method to draw the best out of neural generation. By sampling text from the dynamic nucleus of the probability distribution,
              which allows for diversity while effectively truncating the less reliable tail of the distribution,
              the resulting text better demonstrates the quality of human text,
              yielding enhanced diversity without sacrificing fluency and coherence.}
}
@article{Bender_2021,
  title   = {On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? &#x1f99c;},
  year    = {2021},
  author  = {Emily M. Bender and Emily M. Bender and Emily M. Bender and Emily M. Bender and Timnit Gebru and Timnit Gebru and Timnit Gebru and Angelina McMillan-Major and Angelina McMillan-Major and Shmargaret Shmitchell and Shmargaret Shmitchell},
  doi     = {10.1145/3442188.3445922},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {3133702157},
  journal = {Conference on Fairness,
             Accountability and Transparency}
}
@article{Vaswani_2017,
  title   = {Attention is All you Need},
  year    = {2017},
  author  = {Ashish Vaswani and Ashish Vaswani and Noam Shazeer and Noam Shazeer and Niki Parmar and Niki Parmar and Jakob Uszkoreit and Jakob Uszkoreit and Llion Jones and Llion Jones and Aidan N. Gomez and Aidan N. Gomez and Łukasz Kaiser and Lukasz Kaiser and Illia Polosukhin and Illia Polosukhin},
  doi     = {null},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {2963403868},
  journal = {Neural Information Processing Systems}
}
@article{Steinebach_2024,
  title   = {Natural Language Steganography by ChatGPT},
  year    = {2024},
  author  = {Martin Steinebach},
  doi     = {10.1145/3664476.3670930},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {null},
  journal = {ARES}
}
@article{Liao_2024,
  title   = {Co-Stega: Collaborative Linguistic Steganography for the Low Capacity Challenge in Social Media},
  year    = {2024},
  author  = {Guorui Liao and Jinshuai Yang and Kaiyi Pang and Yongfeng Huang},
  doi     = {10.1145/3658664.3659657},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {null},
  journal = {Information Hiding and Multimedia Security Workshop}
}
@article{Ding_2023,
  title   = {Discop: Provably Secure Steganography in Practice Based on "Distribution Copies"},
  year    = {2023},
  author  = {Jinyang Ding and Kejiang Chen and Yaofei Wang and Na Zhao and Weiming Zhang and Nenghai Yu},
  doi     = {10.1109/sp46215.2023.10179287},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {4384948607},
  journal = {IEEE Symposium on Security and Privacy}
}
@article{Zhang_2020,
  title   = {Linguistic Steganography: From Symbolic Space to Semantic Space},
  year    = {2020},
  author  = {Siyu Zhang and Si-Yu Zhang and Zhongliang Yang and Zhongliang Yang and Jinshuai Yang and Jinshuai Yang and Yudong Huang and Yongfeng Huang},
  doi     = {10.1109/lsp.2020.3042413},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {3109254234},
  journal = {IEEE Signal Processing Letters}
}
@article{Munyer_2023,
  title   = {DeepTextMark: A Deep Learning-Driven Text Watermarking Approach for Identifying Large Language Model Generated Text},
  year    = {2023},
  author  = {Travis J. E. Munyer and A. Tanvir and A. Das and Xin Zhong},
  doi     = {10.1109/access.2024.3376693},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {null},
  journal = {IEEE Access}
}
@article{Bubeck_2023,
  title   = {Sparks of Artificial General Intelligence: Early experiments with GPT-4},
  year    = {2023},
  author  = {Sébastien Bubeck and Varun Chandrasekaran and Ronen Eldan and J. Gehrke and Eric Horvitz and Ece Kamar and Peter Lee and Y. Lee and Yuan-Fang Li and Scott M. Lundberg and Harsha Nori and Hamid Palangi and Marco Tulio Ribeiro and Yi Zhang},
  doi     = {null},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {null},
  journal = {arXiv.org}
}
@article{Achiam_2023,
  title   = {GPT-4 Technical Report},
  year    = {2023},
  doi     = {null},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {null},
  journal = {null}
}
@article{Wang_2023,
  title   = {Hi-Stega: A Hierarchical Linguistic Steganography Framework Combining Retrieval and Generation},
  year    = {2023},
  author  = {Huili Wang and Zhongliang Yang and Jinshuai Yang and Yue Gao and Yudong Huang},
  doi     = {10.1007/978-981-99-8073-4_4},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {4388660683},
  journal = {International Conference on Neural Information Processing}
}
@article{Ding_2024,
  title   = {Context-Aware Linguistic Steganography Model Based on Neural Machine Translation},
  year    = {2024},
  author  = {Changhao Ding and Zhangjie Fu and Zhongliang Yang and Qi Yu and Daqiu Li and Yong Huang},
  doi     = {10.1109/taslp.2023.3340601},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {null},
  journal = {IEEE/ACM Transactions on Audio Speech and Language Processing}
}
@article{Ji_2024,
  title   = {A Principled Approach to Natural Language Watermarking},
  year    = {2024},
  author  = {Zhe Ji and Qiansiqi Hu and Yicheng Zheng and Liyao Xiang and Xinbing Wang},
  doi     = {10.1145/3664647.3681544},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {null},
  journal = {ACM Multimedia}
}
@article{Lin_2024,
  title   = {Zero-shot Generative Linguistic Steganography},
  year    = {2024},
  author  = {Ke Lin and Yiyang Luo and Zijian Zhang and Ping Luo},
  doi     = {10.48550/arxiv.2403.10856},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {null},
  journal = {North American Chapter of the Association for Computational Linguistics}
}
@article{Kaptchuk_2021,
  title   = {Meteor: Cryptographically Secure Steganography for Realistic Distributions},
  year    = {2021},
  author  = {Gabriel Kaptchuk and Gabriel Kaptchuk and Tushar M. Jois and Tushar M. Jois and Matthew Green and Matthew Green and Aviel D. Rubin and Aviel D. Rubin},
  doi     = {10.1145/3460120.3484550},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {3211484452},
  journal = {IACR Cryptology ePrint Archive}
}
@article{Papineni_2002,
  title   = {Bleu: a Method for Automatic Evaluation of Machine Translation},
  year    = {2002},
  author  = {Kishore Papineni and Kishore Papineni and Salim Roukos and Salim Roukos and Todd J. Ward and Todd Ward and Wei-Jing Zhu and Wei-Jing Zhu},
  doi     = {10.3115/1073083.1073135},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {2101105183},
  journal = {Annual Meeting of the Association for Computational Linguistics}
}
@article{Zhang_2021,
  title   = {Provably Secure Generative Linguistic Steganography},
  year    = {2021},
  author  = {Siyu Zhang and Zhongliang Yang and Jinshuai Yang and Yongfeng Huang},
  doi     = {10.18653/v1/2021.findings-acl.268},
  pmid    = {null},
  pmcid   = {null},
  mag_id  = {null},
  journal = {Findings}
}
